version: '3.8'

services:
  redis:
    image: redis:7-alpine
    container_name: think-ai-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    command: redis-server --appendonly yes

  think-ai:
    build: .
    container_name: think-ai-app
    ports:
      - "7860:7860"
    volumes:
      - ./conversation_memory.jsonl:/app/conversation_memory.jsonl
      - ./cache_data:/app/cache_data
    environment:
      - OLLAMA_BASE_URL=http://host.docker.internal:11434/api/chat
      - PYTHONUNBUFFERED=1
    depends_on:
      - redis
    restart: unless-stopped
    extra_hosts:
      - "host.docker.internal:host-gateway"

volumes:
  redis_data: